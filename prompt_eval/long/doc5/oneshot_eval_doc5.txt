<|user|>
You are a summarization model. Generate a summary of a text taken from a scientific paper by following the guidelines below:

   1. Divide the summary into subsections. Use either subsections present in the text, or create subsections based on the key topics discussed in the text. Subsections must be placed in the chronological order.
   2. Include the information (e.g., definition of a concept) that helps to understand the topic of subsection if it is provided in the text. Otherwise, ignore this step.
   3. Per subsection, list the cited authors that contributed to the topic of the subsection in chronological order. The list must be in the bullet point form. The examples of how authors can be notated in the text are "Author et al. (2019)" or "(Author et al., 2017)" or "(Author et al., 2017; Author et al., 1998; Author et al., 2022)".
   4. For each author's entry, include the contribution they made, according to the text, on the topic of the subsection. These form the authors - contribution pair. There are two ways to spot a contribution:
      - When "Author et al. (2019)" notation is met in the text, the contribution follows next. It usually ends within the same sentence if not grammatically stated otherwise.
      - When the authors’ notation within the brackets is met (e.g. "(Author et al., 2017)" or "(Author et al., 2017; Author et al., 1998; Author et al., 2022)"), the contribution can be found before the brackets. Do not include information after the brackets in the contribution.
   5. Some contributions are proposed by the authors of the target text. These contributions can be recognized by the use of the forms of the word “we” in the text (e.g., “our approach”, ”our motivation”, “we aim”).
   6. Use one bullet point to represent the authors - contribution pair.
   7. The author - contribution notation must follow one of these structures: 
      - If one author:
         - Author et al., 2020: contribution
      - If multiple authors: 
         - Author et al., 2020, Author et al., 2023, Author et al., 2008: contribution
      - If authors of the paper:
         - Authors of the paper: contribution
   8. Be precise in the body of contribution:
      - Do not use information not directly supported by the text
      - Do not leave out information necessary to understand the summary without reading the text (e.g., abbreviation definitions)
      - Be brief, include only the essential information

Ensure that your answer is accurate, brief and doesn't contain any information not directly supported by the text. Ensure that the summary includes all authors mentioned in the text and their contributions.

Text: "Eye-tracking for NLP.  Eye-tracking data have proved to be associated with language comprehension activity in human brains by numerous research in neuroscience (Rayner, 1998;Henderson and Ferreira, 1993).  In cognitively motivated NLP, several studies have investigated the impact of eye-tracking data on NLP tasks.  In early works, these signals have been used in machine learning approaches to NLP tasks, such as part-of-speech tagging (Barrett et al., 2016), multiword expression extraction (Rohanian et al., 2017), syntactic category prediction (Barrett and Sgaard, 2015).  In neural models, eyetracking data are combined with word embeddings to improve various NLP tasks, such as sentiment analysis (Mishra et al., 2017) and NER (Hollenstein and Zhang, 2019).  Eye-tracking data have also been used to enhance or constrain neural attention in (Barrett et al., 2018;Sood et al., 2020b,a; Takmaz et al., 2020).   EEG for NLP.  Electroencephalography (EEG) measures potentials fluctuations caused by the activity of neurons in cerebral cortex.  The exploration of EEG data in NLP tasks is relatively limited.  Chen et al. (2012) improve the performance of automatic speech recognition (ASR) by using EEG signals to classify the speaker's mental state.  Hollenstein et al. (2019a) incorporate EEG signals into NLP tasks, including NER, relation extraction and sentiment analysis.  Additionally, Muttenthaler et al. (2020) leverage EEG features to regularize attention on relation extraction.   Adversarial Learning.  The concept of adversarial training originates from the Generative Adversarial Nets (GAN) (Goodfellow et al., 2014) in computer vision.  Since then, it has been also applied in NLP (Denton et al., 2015;Ganin et al., 2016).  Recently, a great variety of studies attempt to introduce adversarial training into multi-task learning in NLP tasks, such as Chinese NER (Cao et al., 2018), crowdsourcing learning (Yang et al., 2018), cross-lingual transfer learning (Chen et al., 2018;Kim et al., 2017), just name a few.  Different from these studies, we use adversarial learning to deeply align cognitive modality to textual modality at the sentence level. "<|end|>
<|assistant|>
1. **Eye-Tracking for NLP**:
   - **Rayner (1998)** and **Henderson and Ferreira (1993)** associated eye-tracking data with language comprehension activity in human brains.
   - In early works, eye-tracking signals were used in machine learning approaches for NLP tasks:
 	    - **Barrett et al. (2016)** applied eye-tracking data to part-of-speech tagging.
 	    - **Rohanian et al. (2017)** used eye-tracking data for multiword expression extraction.
 	    - **Barrett and Sgaard (2015)** explored eye-tracking data in syntactic category prediction.
   - Neural models combined eye-tracking data with word embeddings to improve NLP tasks:
 	    - **Mishra et al. (2017)** used eye-tracking data for sentiment analysis.
 	    - **Hollenstein and Zhang (2019)** incorporated eye-tracking data into named entity recognition (NER).
   - Eye-tracking data also influenced neural attention:
 	    - **Barrett et al. (2018)** and **Sood et al. (2020b,a)** explored enhancing or constraining neural attention using eye-tracking data.
 	    - **Takmaz et al. (2020)** investigated similar approaches.

2. **EEG for NLP**:
   - Electroencephalography (EEG) measures neuronal activity in the cerebral cortex.
   - Limited exploration of EEG data in NLP tasks:
 	    - **Chen et al. (2012)** improved automatic speech recognition (ASR) by classifying speaker mental states using EEG signals.
 	    - **Hollenstein et al. (2019a)** incorporated EEG signals into NLP tasks, including NER, relation extraction, and sentiment analysis.
 	    - **Muttenthaler et al. (2020)** used EEG features to regularize attention in relation extraction.

3. **Adversarial Learning in NLP**:
   - Adversarial training, originating from Generative Adversarial Nets (GANs) in computer vision, has been applied in NLP:
        - **Denton et al. (2015)** and **Ganin et al. (2016)** explored adversarial training.
    - Recent studies introduced adversarial training into multi-task NLP learning:
        - **Cao et al. (2018)** applied adversarial training to Chinese named entity recognition (NER).
        - **Yang et al. (2018)** used adversarial training for crowdsourcing learning.
        - **Chen et al. (2018)** and **Kim et al. (2017)** explored cross-lingual transfer learning using adversarial techniques.
        - The current study focuses on using adversarial learning to align cognitive modality with textual modality at the sentence level.<|end|>
<|user|>
You are a summarization model. Generate a summary of a text taken from a scientific paper by following the guidelines below:

   1. Divide the summary into subsections. Use either subsections present in the text, or create subsections based on the key topics discussed in the text. Subsections must be placed in the chronological order.
   2. Include the information (e.g., definition of a concept) that helps to understand the topic of subsection if it is provided in the text. Otherwise, ignore this step.
   3. Per subsection, list the cited authors that contributed to the topic of the subsection in chronological order. The list must be in the bullet point form. The examples of how authors can be notated in the text are "Author et al. (2019)" or "(Author et al., 2017)" or "(Author et al., 2017; Author et al., 1998; Author et al., 2022)".
   4. For each author's entry, include the contribution they made, according to the text, on the topic of the subsection. These form the authors - contribution pair. There are two ways to spot a contribution:
      - When "Author et al. (2019)" notation is met in the text, the contribution follows next. It usually ends within the same sentence if not grammatically stated otherwise.
      - When the authors’ notation within the brackets is met (e.g. "(Author et al., 2017)" or "(Author et al., 2017; Author et al., 1998; Author et al., 2022)"), the contribution can be found before the brackets. Do not include information after the brackets in the contribution.
   5. Some contributions are proposed by the authors of the target text. These contributions can be recognized by the use of the forms of the word “we” in the text (e.g., “our approach”, ”our motivation”, “we aim”).
   6. Use one bullet point to represent the authors - contribution pair.
   7. The author - contribution notation must follow one of these structures: 
      - If one author:
         - Author et al., 2020: contribution
      - If multiple authors: 
         - Author et al., 2020, Author et al., 2023, Author et al., 2008: contribution
      - If authors of the paper:
         - Authors of the paper: contribution
   8. Be precise in the body of contribution:
      - Do not use information not directly supported by the text
      - Do not leave out information necessary to understand the summary without reading the text (e.g., abbreviation definitions)
      - Be brief, include only the essential information

Ensure that your answer is accurate, brief and doesn't contain any information not directly supported by the text. Ensure that the summary includes all authors mentioned in the text and their contributions.

Text: "Various approaches to the compositional generalization challenge posted by the CFQ dataset has been explored in prior or contemporary works, including Guo et al. (2020), Das et al. (2021), and Herzig et al. (2021).  These approaches are discussed in more detail in Section 4.   Another promising approach that has received relatively less attention so far is grammar induction, which can potentially derive grammar rules directly from question-query pairs.  Grammar induction methods, such as Zettlemoyer and Collins (2005), typically assumes a limited set of grammar rules to bootstrap the model, and then search some grammar spaces to find grammars that can lead to successful parsing of observed questions.   The idea of grammar induction has inspired various work that to different extent solved the SCAN dataset, such as Nye et al. (2020) or Chen et al. (2020).  The advantage of grammar induction methods is that they can potentially identify the complete set of transformation rules and thus attain perfect compositional generalization.  However, grammar induction methods are generally search-based, which limits their scalability to long sentences due to the size of search spaces.   Additionally, there has been considerable research in the semantic parsing literature to design neural network architectures that incorporate different query structures, including tree (Dong and Lapata, 2016), graph (Buys and Blunsom, 2017;Damonte et al., 2017;Lyu and Titov, 2018;Fancellu et al., 2019).  However, these architectures only incorporating query structures without incorporating syntactic structures in questions.  Our ablation study (Table 3) indicates that only incorporating query structure is insufficient for compositional generalization.  Our graph decoder alone only attains performance on bar with T5 models.   Similar to our work, Russin et al. (2019) also proposes to improve the compositional generalization of seq2seq models using attention.  However, their work only studies token-level attention without consideration of syntactic or semantic structures.  Both Russin et al. (2019) and Gordon et al. (2020) use part-of-speech (PoS) tags to attain some level of invariance among words that share the same PoS.   Finally, in the domain of semantic parsing, prior to Keysers et al. (2020), Finegan-Dollak et al. (2018) proposed to split datasets such that training and test sets contain no common SQL patterns.  Although this approach increases task difficulty, different SQL query patterns may still share similar substructures, which enables neural networks to solve the tasks relatively easily using the "mix-and-match" strategy (Lake and Baroni, 2018)."<|end|>
<|assistant|>