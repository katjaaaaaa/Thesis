<|user|>
You are a summarization model. Generate a summary of a text taken from a scientific paper by following the guidelines below:

   1. Divide the summary into subsections. Use either subsections present in the text, or create subsections based on the key topics discussed in the text. Subsections must be placed in the chronological order.
   2. Include the information (e.g., definition of a concept) that helps to understand the topic of subsection if it is provided in the text. Otherwise, ignore this step.
   3. Per subsection, list the cited authors that contributed to the topic of the subsection in chronological order. The list must be in the bullet point form. The examples of how authors can be notated in the text are "Author et al. (2019)" or "(Author et al., 2017)" or "(Author et al., 2017; Author et al., 1998; Author et al., 2022)".
   4. For each author's entry, include the contribution they made, according to the text, on the topic of the subsection. These form the authors - contribution pair. There are two ways to spot a contribution:
      - When "Author et al. (2019)" notation is met in the text, the contribution follows next. It usually ends within the same sentence if not grammatically stated otherwise.
      - When the authors’ notation within the brackets is met (e.g. "(Author et al., 2017)" or "(Author et al., 2017; Author et al., 1998; Author et al., 2022)"), the contribution can be found before the brackets. Do not include information after the brackets in the contribution.
   5. Some contributions are proposed by the authors of the target text. These contributions can be recognized by the use of the forms of the word “we” in the text (e.g., “our approach”, ”our motivation”, “we aim”).
   6. Use one bullet point to represent the authors - contribution pair.
   7. The author - contribution notation must follow one of these structures: 
      - If one author:
         - Author et al., 2020: contribution
      - If multiple authors: 
         - Author et al., 2020, Author et al., 2023, Author et al., 2008: contribution
      - If authors of the paper:
         - Authors of the paper: contribution
   8. Be precise in the body of contribution:
      - Do not use information not directly supported by the text
      - Do not leave out information necessary to understand the summary without reading the text (e.g., abbreviation definitions)
      - Be brief, include only the essential information

Ensure that your answer is accurate, brief and doesn't contain any information not directly supported by the text. Ensure that the summary includes all authors mentioned in the text and their contributions.

Text: "The automatic generation of paraphrases is important for many downstream NLP applications and it has attracted a number of different approaches.  Early researches included rule-based approaches (McKeown, 1979;Meteer and Shaked, 1988) and data-driven methods (Madnani and Dorr, 2010).  With the advances of neural networks, recent approaches tackle this problem by treating it as a sequence-to-sequence language generation task.  Prakash et al. (2016) proposed to modify the networks structure to improve the generation quality.  Cao et al. (2017), Wang et al. (2019), and Kazemnejad et al. (2020) proposed to improve the model performance by leveraging external resources, including phrase dictionary, semantic annotations, and an off-the-shelf pre-trained neural retriever.  Other works proposed to adopt techniques like reinforcement learning (Li et al., 2018) and unsupervised learning (Roy and Grangier, 2019) for this task.   While achieving satisfactory results, these above methods do not offer users the way to control the generation process in a fine-grained way.  To incorporate controllability into the generation model, different approaches have been proposed.  Iyyer et al. (2018) trained the model to produce the paraphrased sentence with a given syntax.  Li et al. (2019) proposed to adopt an external word aligner to train the model to generate paraphrases from different levels.  In Fu et al. (2019)'s work, the model generates paraphrases by planning the neighbour of words and realizing the complete sentence. "<|end|>
<|assistant|>