<|user|>
You are a summarization model. Generate a summary of a text taken from a scientific paper. Divide the summary into key concepts and/or subsections. Divide the summary into subsections. Use either subsections present in the text, or create subsections based on the key topics discussed in the text. Subsections must be placed in the chronological order. Per subsection, list the cited authors that contributed to the topic of the subsection in chronological order. The list must be in the bullet point form. The examples of how authors can be notated in the text are "Author et al. (2019)" or "(Author et al., 2017)". If no authors are introduced, assign the contribution to the authors of the paper the text was taken from. The structure of each contribution must be as following:
- Author at al. (2020): contribution
To notate the authors of the paper the text was taken from, use the following structure:
- Authors of the paper: contribution
Ensure that your answer is accurate and doesn't contain any information not directly supported by the text.

Text: "Domain adaptation strategies can be separated into four categories: data selection, data generation, instance weighting and model interpolation Chu and Wang (2018).  We focus our discussion on data selection and instance weighting, as these are closely related to our approach.   Data-centric methods.  Models are trained using in-domain and out-of-domain data to evaluate out-of-domain data and compute a similarity score.  Using a cut-off threshold on these scores the training data can be selected.  Language Models Moore and Lewis (2010); Axelrod et al. (2011); Duh et al. (2013) or joint models Cuong and Sima'an (2014); Durrani et al. (2015) can traditionally be applied to score corpora.  Recently convolutional neural networks (CNN) Chen et al. (2016) were used.  Our work has similarities to this work but uses instance weighting rather than data selection.   In settings where the amount of parallel training corpora is not sufficient, generating pseudo-parallel sentences by information retrieval Utiyama and Isahara (2003), self-enhancing Lambert et al. (2011) or parallel word embeddings Marie and Fujita (2017).  Aside from generating sentences, other approaches generate monolingual n-grams Wang et al. (2014) or parallel phrase pairs Chu (2015).   In general, data-centric methods (data selection and data generation) are not SMT specific and can be directly applied to NMT.  However, because these methods are not directly related to NMT's training criterion, they only lead to minor improvements Wang et al. (2017a).   Model-centric methods.  Instance Weighting is a technique from SMT and was introduced to NMT as well Wang et al. (2017b).  An in-domain language model was trained to measure the similarity between sentences and the in-domain data via cross-entropy.  The weights are then integrated into the training objective.  We improve on their work by using state-of-the-art neural classifiers and showing that they are more effective than cross-entropy.   Two works that are closer to our work are Wang et al. (2018) and Chen et al. (2017).  In Wang et al. (2018) they generate sentence embeddings for all in-domain sentences and then measure the distance between every sentence and the in-domain core.  The underlying assumption is that the core of all in-domain sentence embeddings is atypical representative and proximity in their sentence embeddings indicates being part of the same domain.  This approach is appropriate when we have in-domain parallel text, but we study a different scenario, with no access to in-domain parallel text, which means the encoder has no access to in-domain training examples.  In Chen et al. (2017) a domain classifier is incorporated into the NMT system, using features from the encoder to distinguish between in-domain and out-of-domain data.  The classifier probabilities are used to weight sentences with regard to their similarity to in-domain data, when training the neural network.  Scaling the loss function is similar to multiplying the learning rate with the instance weight.  The classifier and NMT are trained at the same time, whereas we chose an approach with pretrained neural classifiers which are trained on a small amount of monolingual data (the scenario we study) with no access to parallel in-domain data.   Finally, while some previous work we have mentioned did look at various ways to use domain classification, such previous work has not focused on how to weight the classifier probabilities for effective use in NMT, which we showed is important for obtaining translation quality improvements, particularly when using neural classifiers which can be overconfident. "<|end|>
<|assistant|>