{
 "results": " 1. **Domain Adaptation Strategies**:\n   - Chu and Wang (2018) categorized domain adaptation strategies into four categories: data selection, data generation, instance weighting, and model interpolation.\n\n2. **Data-Centric Methods**:\n   - Models are trained using in-domain and out-of-domain data to evaluate out-of-domain data and compute a similarity score.\n   - Language Models:\n     - Moore and Lewis (2010)\n     - Axelrod et al. (2011)\n     - Duh et al. (2013)\n   - Joint Models:\n     - Cuong and Sima'an (2014)\n     - Durrani et al. (2015)\n   - Convolutional Neural Networks (CNN):\n     - Chen et al. (2016)\n   - The authors of the paper's work are similar to Chen et al. (2016) but use instance weighting rather than data selection.\n\n3. **Data Generation Methods**:\n   - Generating pseudo-parallel sentences by information retrieval:\n     - Utiyama and Isahara (2003)\n   - Self-enhancing monolingual n-grams:\n     - Lambert et al. (2011)\n   - Parallel word embeddings:\n     - Marie and Fujita (2017)\n   - Generating parallel phrase pairs:\n     - Chu (2015)\n\n4. **Model-Centric Methods**:\n   - Instance Weighting:\n     - Introduced to NMT from SMT by Wang et al. (2017b).\n   - Domain Classifier:\n     - Incorporated into the NMT system by Wang et al. (2018).\n   - The authors of the paper improved on the work of Wang et al. (2017b) by using state-of-the-art neural classifiers.\n   - The authors of the paper's work are similar to Wang et al. (2018) and Chen et al. (2017) in their approach to domain classification.\n\n5. **Contributions of the Authors**:\n   - Chu and Wang (2018): Domain adaptation strategies categorization.\n   - Moore and Lewis (2010), Axelrod et al. (2011), Duh et al. (2013), Cuong and Sima'an (2014), Durrani et al. (2015): Data-centric methods.\n   - Chen et al. (2016, 2017, 2018): Similarities to data-centric methods and model-centric methods, respectively.\n   - The authors of the paper: Improved on previous work by using state-of-the-art neural classifiers and showing the importance of weighting classifier probabilities for effective use in NMT."
}