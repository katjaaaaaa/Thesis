<|user|>
You are a summarization model. Generate a summary of a text taken from a scientific paper. Divide the summary into key concepts and/or subsections. Per concept list each cited paper's authors and contributions they've made. The examples of how authors can be notated in the text are "Author et al. (2019)" or "(Author et al., 2017)". If no authors are introduced, assign the contribution to the authors of the paper the text was taken from. The structure of each contribution must be as following:
- Author at al. (2020): contribution
To notate the authors of the paper the text was taken from, use the following structure:
- Authors of the paper: contribution
Ensure that your answer is accurate and doesn't contain any information not directly supported by the text.

Text: "Eye-tracking for NLP.  Eye-tracking data have proved to be associated with language comprehension activity in human brains by numerous research in neuroscience (Rayner, 1998;Henderson and Ferreira, 1993).  In cognitively motivated NLP, several studies have investigated the impact of eye-tracking data on NLP tasks.  In early works, these signals have been used in machine learning approaches to NLP tasks, such as part-of-speech tagging (Barrett et al., 2016), multiword expression extraction (Rohanian et al., 2017), syntactic category prediction (Barrett and Sgaard, 2015).  In neural models, eyetracking data are combined with word embeddings to improve various NLP tasks, such as sentiment analysis (Mishra et al., 2017) and NER (Hollenstein and Zhang, 2019).  Eye-tracking data have also been used to enhance or constrain neural attention in (Barrett et al., 2018;Sood et al., 2020b,a; Takmaz et al., 2020).   EEG for NLP.  Electroencephalography (EEG) measures potentials fluctuations caused by the activity of neurons in cerebral cortex.  The exploration of EEG data in NLP tasks is relatively limited.  Chen et al. (2012) improve the performance of automatic speech recognition (ASR) by using EEG signals to classify the speaker's mental state.  Hollenstein et al. (2019a) incorporate EEG signals into NLP tasks, including NER, relation extraction and sentiment analysis.  Additionally, Muttenthaler et al. (2020) leverage EEG features to regularize attention on relation extraction.   Adversarial Learning.  The concept of adversarial training originates from the Generative Adversarial Nets (GAN) (Goodfellow et al., 2014) in computer vision.  Since then, it has been also applied in NLP (Denton et al., 2015;Ganin et al., 2016).  Recently, a great variety of studies attempt to introduce adversarial training into multi-task learning in NLP tasks, such as Chinese NER (Cao et al., 2018), crowdsourcing learning (Yang et al., 2018), cross-lingual transfer learning (Chen et al., 2018;Kim et al., 2017), just name a few.  Different from these studies, we use adversarial learning to deeply align cognitive modality to textual modality at the sentence level. "<|end|>
<|assistant|>
## Scientific Paper Summary: Utilizing Cognitive Information in NLP Tasks

This paper explores how incorporating cognitive information, specifically through eye-tracking and EEG data, can improve various NLP tasks.

**Key Concepts**

1. **Eye-tracking for NLP**
	* **Contribution**: Eye-tracking data can be used to enhance NLP tasks through machine learning and neural network approaches.
    	* Examples:
        	* Part-of-speech tagging (Barrett et al., 2016)
        	* Multiword expression extraction (Rohanian et al., 2017)
        	* Syntactic category prediction (Barrett and Sgaard, 2015)
        	* Sentiment analysis (Mishra et al., 2017)
        	* Named Entity Recognition (NER) (Hollenstein and Zhang, 2019)
	* **Contribution**: Eye-tracking data can improve neural attention mechanisms in NLP models (Barrett et al., 2018; Sood et al., 2020b, 2020a; Takmaz et al., 2020).

2. **EEG for NLP**
	* **Contribution**: EEG data holds promise for improving NLP tasks, though research is limited.
    	* Examples:
        	* Automatic speech recognition (ASR) (Chen et al., 2012)
        	* NER, relation extraction, sentiment analysis (Hollenstein et al., 2019a)
        	* Regularizing attention on relation extraction (Muttenthaler et al., 2020)

3. **Adversarial Learning for NLP**
	* **Background**: Adversarial training has been successfully applied in NLP tasks (Denton et al., 2015; Ganin et al., 2016).
	* **This paper**: Proposes a novel application of adversarial learning to align cognitive and textual modalities at the sentence level (not mentioned in cited works).<|end|>
<|user|>
I rated this summary based on the following criteria:
1. Quality of the summary's structure: The summary follows the paper's structure and contains necessary subsections if they were introduced in the paper. In other terms, if the text adds a concept and then provides the cited papers related to the concept, the model must structure the summary to highlight the relation between them.
2. Quality of the summarization: The summary has no hallucinations, and all the information can be found in the source text.
3. Quality of the sources' citations: Each cited paper mentioned in the target paper is introduced in the summary and contains a brief but clear description of what this source's contribution is.
Based on these criteria I ranked the summary as follows:
Quality structure: 1/5
Quality translation: 5/5
Quality citations: 2/5

You are a summarization model. Generate a summary of a text taken from a scientific paper. Divide the summary into key concepts and/or subsections. Per concept list each cited paper's authors and contributions they've made. The examples of how authors can be notated in the text are "Author et al. (2019)" or "(Author et al., 2017)". If no authors are introduced, assign the contribution to the authors of the paper the text was taken from. The structure of each contribution must be as following:
- Author at al. (2020): contribution
To notate the authors of the paper the text was taken from, use the following structure:
- Authors of the paper: contribution
Ensure that your answer is accurate and doesn't contain any information not directly supported by the text.

Text: "Eye-tracking for NLP.  Eye-tracking data have proved to be associated with language comprehension activity in human brains by numerous research in neuroscience (Rayner, 1998;Henderson and Ferreira, 1993).  In cognitively motivated NLP, several studies have investigated the impact of eye-tracking data on NLP tasks.  In early works, these signals have been used in machine learning approaches to NLP tasks, such as part-of-speech tagging (Barrett et al., 2016), multiword expression extraction (Rohanian et al., 2017), syntactic category prediction (Barrett and Sgaard, 2015).  In neural models, eyetracking data are combined with word embeddings to improve various NLP tasks, such as sentiment analysis (Mishra et al., 2017) and NER (Hollenstein and Zhang, 2019).  Eye-tracking data have also been used to enhance or constrain neural attention in (Barrett et al., 2018;Sood et al., 2020b,a; Takmaz et al., 2020).   EEG for NLP.  Electroencephalography (EEG) measures potentials fluctuations caused by the activity of neurons in cerebral cortex.  The exploration of EEG data in NLP tasks is relatively limited.  Chen et al. (2012) improve the performance of automatic speech recognition (ASR) by using EEG signals to classify the speaker's mental state.  Hollenstein et al. (2019a) incorporate EEG signals into NLP tasks, including NER, relation extraction and sentiment analysis.  Additionally, Muttenthaler et al. (2020) leverage EEG features to regularize attention on relation extraction.   Adversarial Learning.  The concept of adversarial training originates from the Generative Adversarial Nets (GAN) (Goodfellow et al., 2014) in computer vision.  Since then, it has been also applied in NLP (Denton et al., 2015;Ganin et al., 2016).  Recently, a great variety of studies attempt to introduce adversarial training into multi-task learning in NLP tasks, such as Chinese NER (Cao et al., 2018), crowdsourcing learning (Yang et al., 2018), cross-lingual transfer learning (Chen et al., 2018;Kim et al., 2017), just name a few.  Different from these studies, we use adversarial learning to deeply align cognitive modality to textual modality at the sentence level. "<|end|>
<|assistant|>

1. **Eye-tracking for NLP:**
   - Rayner (1998), Henderson and Ferreira (1993): Associated eye-tracking data with language comprehension activity.
   - Barrett et al. (2016): Used eye-tracking data in machine learning approaches for part-of-speech tagging.
   - Rohanian et al. (2017): Applied eye-tracking data in multiword expression extraction.
   - Barrett and Sgaard (2015): Utilized eye-tracking data for syntactic category prediction.
   - Mishra et al. (2017): Combined eye-tracking data with word embeddings to enhance sentiment analysis.
   - Hollenstein and Zhang (2019): Incorporated eye-tracking data into named entity recognition (NER).
   - Barrett et al. (2018), Sood et al. (2020), Takmaz et al. (2020): Employed eye-tracking data to enhance or constrain neural attention.

2. **EEG for NLP:**
   - Chen et al. (2012): Improved automatic speech recognition (ASR) using EEG signals to classify the speaker's mental state.
   - Hollenstein et al. (2019a): Integrated EEG signals into various NLP tasks including NER, relation extraction, and sentiment analysis.
   - Muttenthaler et al. (2020): Leveraged EEG features to regulate attention in relation extraction.

3. **Adversarial Learning in NLP:**
   - Goodfellow et al. (2014): Originated the concept of adversarial training in Generative Adversarial Nets (GAN) in computer vision.
   - Denton et al. (2015), Ganin et al. (2016): Applied adversarial training in NLP tasks.
   - Cao et al. (2018): Introduced adversarial training in multi-task learning for Chinese NER.
   - Yang et al. (2018): Applied adversarial training in crowdsourcing learning.
   - Chen et al. (2018), Kim et al. (2017): Employed adversarial training in cross-lingual transfer learning.
   - Authors of the paper: Proposed the use of adversarial learning to align cognitive modality with textual modality at the sentence level.<|end|>
<|user|>
I rated this summary based on the following criteria:
1. Quality of the summary's structure: The summary follows the paper's structure and contains necessary subsections if they were introduced in the paper. In other terms, if the text adds a concept and then provides the cited papers related to the concept, the model must structure the summary to highlight the relation between them.
2. Quality of the summarization: The summary has no hallucinations, and all the information can be found in the source text.
3. Quality of the sources' citations: Each cited paper mentioned in the target paper is introduced in the summary and contains a brief but clear description of what this source's contribution is.
Based on these criteria I ranked the summary as follows:
Quality structure: 5/5
Quality summarization: 4/5
Quality sources: 5/5

You are a summarization model. Generate a summary of a text taken from a scientific paper. Divide the summary into key concepts and/or subsections. Per concept list each cited paper's authors and contributions they've made. The examples of how authors can be notated in the text are "Author et al. (2019)" or "(Author et al., 2017)". If no authors are introduced, assign the contribution to the authors of the paper the text was taken from. The structure of each contribution must be as following:
- Author at al. (2020): contribution
To notate the authors of the paper the text was taken from, use the following structure:
- Authors of the paper: contribution
Ensure that your answer is accurate and doesn't contain any information not directly supported by the text.
Text: "Eye-tracking for NLP.  Eye-tracking data have proved to be associated with language comprehension activity in human brains by numerous research in neuroscience (Rayner, 1998;Henderson and Ferreira, 1993).  In cognitively motivated NLP, several studies have investigated the impact of eye-tracking data on NLP tasks.  In early works, these signals have been used in machine learning approaches to NLP tasks, such as part-of-speech tagging (Barrett et al., 2016), multiword expression extraction (Rohanian et al., 2017), syntactic category prediction (Barrett and Sgaard, 2015).  In neural models, eyetracking data are combined with word embeddings to improve various NLP tasks, such as sentiment analysis (Mishra et al., 2017) and NER (Hollenstein and Zhang, 2019).  Eye-tracking data have also been used to enhance or constrain neural attention in (Barrett et al., 2018;Sood et al., 2020b,a; Takmaz et al., 2020).   EEG for NLP.  Electroencephalography (EEG) measures potentials fluctuations caused by the activity of neurons in cerebral cortex.  The exploration of EEG data in NLP tasks is relatively limited.  Chen et al. (2012) improve the performance of automatic speech recognition (ASR) by using EEG signals to classify the speaker's mental state.  Hollenstein et al. (2019a) incorporate EEG signals into NLP tasks, including NER, relation extraction and sentiment analysis.  Additionally, Muttenthaler et al. (2020) leverage EEG features to regularize attention on relation extraction.   Adversarial Learning.  The concept of adversarial training originates from the Generative Adversarial Nets (GAN) (Goodfellow et al., 2014) in computer vision.  Since then, it has been also applied in NLP (Denton et al., 2015;Ganin et al., 2016).  Recently, a great variety of studies attempt to introduce adversarial training into multi-task learning in NLP tasks, such as Chinese NER (Cao et al., 2018), crowdsourcing learning (Yang et al., 2018), cross-lingual transfer learning (Chen et al., 2018;Kim et al., 2017), just name a few.  Different from these studies, we use adversarial learning to deeply align cognitive modality to textual modality at the sentence level. "<|end|>
<|assistant|>
1. **Eye-Tracking for NLP**:
   - **Rayner (1998)** and **Henderson and Ferreira (1993)** associated eye-tracking data with language comprehension activity in human brains.
   - In early works, eye-tracking signals were used in machine learning approaches for NLP tasks:
 	    - **Barrett et al. (2016)** applied eye-tracking data to part-of-speech tagging.
 	    - **Rohanian et al. (2017)** used eye-tracking data for multiword expression extraction.
 	    - **Barrett and Sgaard (2015)** explored eye-tracking data in syntactic category prediction.
   - Neural models combined eye-tracking data with word embeddings to improve NLP tasks:
 	    - **Mishra et al. (2017)** used eye-tracking data for sentiment analysis.
 	    - **Hollenstein and Zhang (2019)** incorporated eye-tracking data into named entity recognition (NER).
   - Eye-tracking data also influenced neural attention:
 	    - **Barrett et al. (2018)** and **Sood et al. (2020b,a)** explored enhancing or constraining neural attention using eye-tracking data.
 	    - **Takmaz et al. (2020)** investigated similar approaches.

2. **EEG for NLP**:
   - Electroencephalography (EEG) measures neuronal activity in the cerebral cortex.
   - Limited exploration of EEG data in NLP tasks:
 	    - **Chen et al. (2012)** improved automatic speech recognition (ASR) by classifying speaker mental states using EEG signals.
 	    - **Hollenstein et al. (2019a)** incorporated EEG signals into NLP tasks, including NER, relation extraction, and sentiment analysis.
 	    - **Muttenthaler et al. (2020)** used EEG features to regularize attention in relation extraction.

3. **Adversarial Learning in NLP**:
   - Adversarial training, originating from Generative Adversarial Nets (GANs) in computer vision, has been applied in NLP:
        - **Denton et al. (2015)** and **Ganin et al. (2016)** explored adversarial training.
    - Recent studies introduced adversarial training into multi-task NLP learning:
        - **Cao et al. (2018)** applied adversarial training to Chinese named entity recognition (NER).
        - **Yang et al. (2018)** used adversarial training for crowdsourcing learning.
        - **Chen et al. (2018)** and **Kim et al. (2017)** explored cross-lingual transfer learning using adversarial techniques.
        - The current study focuses on using adversarial learning to align cognitive modality with textual modality at the sentence level.<|end|>
<|user|>
I rated this summary based on the following criteria:
1. Quality of the summary's structure: The summary follows the paper's structure and contains necessary subsections if they were introduced in the paper. In other terms, if the text adds a concept and then provides the cited papers related to the concept, the model must structure the summary to highlight the relation between them.
2. Quality of the summarization: The summary has no hallucinations, and all the information can be found in the source text.
3. Quality of the sources' citations: Each cited paper mentioned in the target paper is introduced in the summary and contains a brief but clear description of what this source's contribution is.
Based on these criteria I ranked the summary as follows:
Quality structure: 5/5
Quality summarization: 5/5
Quality sources: 4/5

You are a summarization model. Generate a summary of a text taken from a scientific paper. Divide the summary into key concepts and/or subsections. Per concept list each cited paper's authors and contributions they've made. The examples of how authors can be notated in the text are "Author et al. (2019)" or "(Author et al., 2017)". If no authors are introduced, assign the contribution to the authors of the paper the text was taken from. The structure of each contribution must be as following:
- Author at al. (2020): contribution
To notate the authors of the paper the text was taken from, use the following structure:
- Authors of the paper: contribution
Ensure that your answer is accurate and doesn't contain any information not directly supported by the text.
For each example article summary a raking is provided. The criteria of the ratings are provided above.
Base the generated summary on the summaries above that received high ratings, and avoid the practices used in the summaries with low ratings.

Text:"Approaches to disfluency detection task fall into three main categories: noisy channel models, parsing-based approaches and sequence tagging approaches.  Noisy channel models (NCMs) (Johnson and Charniak, 2004;Johnson et al., 2004) use complex tree adjoining grammar (TAG) (Shieber and Schabes, 1990) based channel models to find the "rough copy" dependencies between words.  The channel model uses the similarity between the reparandum and the repair to allocate higher probabilities to exact copy reparandum words.  Using the probabilities of TAG channel model and a bigram language model (LM) derived from training data, the NCM generates n-best disfluency analyses for each sentence at test time.  The analyses are then reranked using a language model which is sensitive to the global properties of the sentence, such as a syntactic parser based LM (Johnson and Charniak, 2004;Johnson et al., 2004).  Some works have shown that rescoring the n-best analyses with external n-gram (Zwarts and Johnson, 2011) and deep learning LMs (Jamshid Lou and Johnson, 2017) trained on large speech and non-speech corpora, and using the LM scores along with other features (i.e.  pattern match and NCM ones) into a MaxEnt reranker (Johnson et al., 2004) improves the performance of the baseline NCM, although this creates complex runtime dependencies.   Parsing-based approaches detect disfluencies while simultaneously identifying the syntactic structure of the sentence.  Typically, this is achieved by augmenting a transition-based dependency parser with anew action to detect and remove the disfluent parts of the sentence and their dependencies from the stack (Rasooli and Tetreault, 2013;Honnibal and Johnson, 2014;Yoshikawa et al., 2016).  Joint parsing and disfluency detection can compare favorably to pipelined approaches, but requires large annotated treebanks containing both disfluent and syntatic structures for training.   Our proposed approach, based on an autocorrelational neural network (ACNN), belongs to the class of sequence tagging approaches.  These approaches use classification techniques such as conditional random fields (Liu et al., 2006;Ostendorf and Hahn, 2013;Zayats et al., 2014;Ferguson et al., 2015), hidden Markov models (Liu et al., 2006;Schuler et al., 2010) and deep learning based models (Hough and Schlangen, 2015;Zayats et al., 2016) to label individual words as fluent or disfluent.  In much of the previous work on sequence tagging approaches, improved performance has been gained by proposing increasingly complicated labeling schemes.  In this case, a model with begin-inside-outside (BIO) style states which labels words as being inside or outside of edit region is usually used as the baseline sequence tagging model.  Then in order to come up with different pattern matching lexical cues for repetition and correction disfluencies, they extend the baseline state space with new explicit repair states to consider the words at repair region, in addition to edit region (Ostendorf and Hahn, 2013;Zayats et al., 2014, 2016).  A model which uses such labeling scheme may generate illegal label sequences at test time.  As a solution, integer linear programming (ILP) constraints are applied to the output of classifier to avoid inconsistencies between neighboring labels (Georgila, 2009;Georgila et al., 2010;Zayats et al., 2016).  This contrasts with our more straightforward approach, which directly labels words as being fluent or disfluent, and does not require any post-processing or annotation modifications.   The most similar work to ours is recent work by Zayats et al. (2016) that investigated the performance of a bidirectional long-short term memory network (BLSTM) for disfluency detection.  Zayats et al. (2016) reported that a BLSTM operating only on words underperformed the same model augmented with hand-crafted pattern match features and POS tags by 7% in terms of f-score.  In addition to lexically grounded features, some works incorporate prosodic information extracted from speech (Kahn et al., 2005;Ferguson et al., 2015;Tran et al., 2018).  In this work, our primary motivation is to rectify the architectural limitations that prevent deep neural networks from automatically learning appropriate features from words alone.  Therefore, our proposed model eschews manually engineered features and other representations derived from dependency parsers, language models or tree adjoining grammar transducers that are used to find "rough copy" dependencies.  Instead, we aim to capture these kinds of dependencies automatically. "<|end|>
<|assistant|>