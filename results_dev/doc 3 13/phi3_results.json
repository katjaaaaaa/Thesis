{
 "zeroshot": [
  {
   "generated_text": " Key Concepts:\n\n1. HappyDB: \n   - <Authors goes here>: <HappyDB is the first crowdsourced corpus of happy moments which can be used for understanding the language people use to describe happy events.>\n\n2. Crowdsourced Datasets in Mental Health:\n   - Althoff et al. (Althoff et al., 2016): <conducted a large scale analysis on counseling conversational logs collected from short message services (SMS) for mental illness study. They studied how various linguistic aspects of conversations are correlated with conversation outcomes.>\n   - Mihalcea et al. (Mihalcea and Liu, 2006): <performed text analysis on blog posts from LiveJournal (where posts can be assigned happy/sad tags by their authors).>\n   - Lin et al. (Lin et al., 2016): <measured stress from short texts by identifying the stressors and the stress levels. They classified tweets into 12 stress categories defined by the stress scale in (Holmes and Rahe, 1967).>\n\n3. Crowdsourced Datasets and Natural Language Techniques:\n   - Rajpurkar et al. (Rajpurkar et al., 2016): <created a largescale dataset for question-answering. The crowdsourced workers were asked to create questions based on a paragraph obtained from Wikipedia. They employed MTurk workers with strong experience and a high approval rating to ensure the quality of the dataset.>\n\n4. Comparison between SQuAD and HappyDB:\n   - <Authors goes here>: <HappyDB is similar to SQuAD in terms of the scale of the crowdsourced dataset. However, unlike SQuAD, which was designed specifically for studying the question answering problem, the problems that HappyDB can be used for are more open-ended.>"
  }
 ],
 "oneshot": [
  {
   "generated_text": " **HappyDB: Crowdsourced Corpus of Happy Moments**\n\n        - **Authors of the Paper**: HappyDB is the first crowdsourced corpus of happy moments, which can be used for understanding the language people use to describe happy events. It is similar to SQuAD in terms of the scale of the crowdsourced dataset. However, unlike SQuAD, which was designed specifically for studying the question answering problem, the problems that HappyDB can be used for are more open-ended.\n\n        **Other Crowdsourced Datasets and Their Contributions**\n\n        - **Althoff et al. (Althoff et al., 2016)**: Conducted a large scale analysis on counseling conversational logs collected from SMS for mental illness study. They studied how various linguistic aspects of conversations are correlated with conversation outcomes.\n        - **Mihalcea et al. (Mihalcea and Liu, 2006)**: Performed text analysis on blog posts from LiveJournal, where posts can be assigned happy/sad tags by their authors.\n        - **Lin et al. (Lin et al., 2016)**: Measured stress from short texts by identifying the stressors and the stress levels. They classified tweets into 12 stress categories defined by the stress scale in (Holmes and Rahe, 1967).\n        - **Rajpurkar et al. (Rajpurkar et al., 2016)**: Created a large scale dataset for question-answering. They employed MTurk workers with strong experience and a high approval rating to ensure the quality of the dataset.\n\n        **Authors of the Paper**: Their work is based on the creation of the HappyDB corpus. They did not select the workers based on their qualification for HappyDB as their task is cognitively easier than SQuAD's and they want to avoid bias in their corpus."
  }
 ],
 "fewshot_rankings": [
  {
   "generated_text": " **Key Concepts and Contributions:**\n\n    **HappyDB Corpus**\n\n    - **Authors of the Paper**: Created the first crowdsourced corpus of happy moments, HappyDB. This corpus can be used for understanding the language people use to describe happy events.\n\n    **Previous Works in Mental Health Datasets**\n\n    - **Althoff et al. (Althoff et al., 2016)**: Conducted a large-scale analysis on counseling conversational logs collected from SMS for mental illness study. They studied how various linguistic aspects of conversations correlate with conversation outcomes.\n\n    - **Mihalcea et al. (Mihalcea and Liu, 2006)**: Performed text analysis on blog posts from LiveJournal. These posts could be assigned happy/sad tags by their authors.\n\n    - **Lin et al. (Lin et al., 2016)**: Measured stress from short texts by identifying stressors and stress levels. They classified tweets into 12 stress categories defined by the stress scale in (Holmes and Rahe, 1967).\n\n    **Other Crowdsourced Datasets and Natural Language Techniques**\n\n    - **SQuAD (Rajpurkar et al., 2016)**: Created a large-scale dataset for question-answering. The crowdsourced workers were asked to create questions based on a paragraph obtained from Wikipedia.\n\n    - **Authors of the Paper**: Did not select the workers based on their qualification for HappyDB to avoid bias in their corpus.\n\n    **Comparison with SQuAD**\n\n    - **Authors of the Paper**: HappyDB is similar to SQuAD in terms of the scale of the crowdsourced dataset. However, unlike SQuAD, which was designed specifically for studying the question-answering problem, the problems that HappyDB can be used for are more open-ended."
  }
 ],
 "fewshot_explanation": [
  {
   "generated_text": " **Key Concepts and Contributions:**\n\n    **HappyDB Corpus**\n\n    - **Authors of the Paper**: Created the first crowdsourced corpus of happy moments, HappyDB. This corpus can be used for understanding the language people use to describe happy events.\n\n    **Previous Research in Mental Health Datasets**\n\n    - **Althoff et al. (Althoff et al., 2016)**: Conducted a large-scale analysis on counseling conversational logs collected from SMS for mental illness study. They studied how various linguistic aspects of conversations correlate with conversation outcomes.\n\n    - **Mihalcea et al. (Mihalcea and Liu, 2006)**: Performed text analysis on blog posts from LiveJournal, where posts can be assigned happy/sad tags by their authors.\n\n    - **Lin et al. (Lin et al., 2016)**: Measured stress from short texts by identifying stressors and stress levels. They classified tweets into 12 stress categories defined by the stress scale in (Holmes and Rahe, 1967).\n\n    **Other Crowdsourced Datasets and Natural Language Techniques**\n\n    - **SQuAD (Rajpurkar et al., 2016)**: Created a large-scale dataset for question-answering. The crowdsourced workers were asked to create questions based on a paragraph obtained from Wikipedia.\n\n    - **Authors of the Paper**: Did not select the workers based on their qualification for HappyDB to avoid bias in their corpus.\n\n    **Comparison with SQuAD**\n\n    - **Authors of the Paper**: HappyDB is similar to SQuAD in terms of the scale of the crowdsourced dataset. However, unlike SQuAD, which was designed specifically for studying the question-answering problem, the problems that HappyDB can be used for are more open-ended."
  }
 ]
}