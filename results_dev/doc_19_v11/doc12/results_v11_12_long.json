{
 "oneshot": " 1. **Computational Humor**:\n   - **Recognition**:\n     - **Cattle and Ma (2018)**: used binary classification for humor recognition.\n     - **Chen and Soo (2018)**: employed binary classification for humor recognition.\n     - **Bertero and Fung (2016)**: utilized binary classification for humor recognition.\n     - **Weller and Seppi (2019)**: applied binary classification for humor recognition.\n     - **Purandare and Litman (2006)**: implemented binary classification for humor recognition.\n   - **Generation**:\n     - **Hossain (2019)**: introduced the dataset for humor generation and trained binary classifiers.\n     - **Authors of the paper**: developed a regression approach to rate humor sequences and used a CNN model inspired by (Zhang and Wallace, 2015) architecture.\n\n2. **Models Used**:\n   - **Hochreiter and Schmidhuber (1997)**: proposed LSTM model architecture.\n   - **Devlin et al. (2019)**: introduced BERT model architecture.\n   - **Zhang and Wallace (2015)**: presented a compact CNN architecture.\n\n3. **Results**:\n   - **Authors of the paper**: achieved promising results for sentence classification using a small CNN model, inspired by (Zhang and Wallace, 2015) architecture.",
 "fewshot_rankings": " 1. **Computational Humor: Recognition and Generation**\n   - **Hossain (2019)**: Introduced the dataset for humor recognition and classification.\n   - **Cattle and Ma (2018); Chen and Soo (2018); Bertero and Fung (2016); Weller and Seppi (2019); Purandare and Litman (2006)**: Employed binary classification models for humor recognition.\n   - **Our paper's contribution**:\n      - We aimed to rate humor on a scale, not just classify it as funny or not.\n      - Utilized a regression approach for grading humor.\n      - Achieved results with a CNN model inspired by Zhang and Wallace (2015).\n      - Authors of the paper: Developed a model that rates humor on a scale and used a compact CNN architecture for efficient computation.",
 "fewshot_explanation": " 1. **Computational Humor: Recognition and Generation**\n   - **Hossain (2019)**: Introduced the dataset for computational humor research.\n   - **Cattle and Ma (2018); Chen and Soo (2018); Bertero and Fung (2016); Weller and Seppi (2019); Purandare and Litman (2006)**: Used binary classification to determine if humor is present.\n   - **Our Paper**: Aimed to rate humor on a scale, not just classify it as funny or not.\n   - **Devlin et al. (2019)**: Utilized BERT for humor recognition tasks.\n   - **Zhang and Wallace (2015)**: Inspired our CNN model architecture.\n   - **Our Paper**: Achieved results with a compact CNN model, outperforming larger models like BERT in terms of computational efficiency.\n\n2. **Humor Generation**\n   - **Our Paper**: Focused on creating models capable of generating humor.\n   - **Zhang and Wallace (2015)**: Provided the architecture for our model, which is smaller and more resource-efficient than others.\n   - **Our Paper**: Achieved promising results with the compact CNN model for humor generation."
}